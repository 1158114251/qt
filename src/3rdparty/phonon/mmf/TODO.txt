TODO list for MMF Phonon backend
--------------------------------

The following items are in rough order of priority.


* Review the latest changes for making video visible on target.  In particular, the temporary hack in qmediaplayer (setting the Qt::WA_TranslucentBackground attribute on the top-level widget, so that the CFbsBitmap used as the window surface is created with a display mode of EColor16MA) needs to be replaced with a change in QtGui.  Some possiblilities are as follows:
1. Change the QS60WindowSurface constructor so that *all* window surfaces are 16MA.  This has some drawbacks:
	- It causes application backgrounds to be transparent, because CFbsBitmap data (including the alpha channel) gets zero-initialized.  This may require the alpha values in the bitmap to be set to 255.
	- Blitting of RGB32 and ABGR Qt pixmaps to a 16MA surface is slower than blitting to 16MU.  This could be alleviated by modifying the software blitting routines.
2. Add a function in QS60WindowSurface, e.g. setAlphaValue(const QRegion& region, int value), allowing the client to set alpha values in the bitmap.  Assuming that WSERV will transfer these values, when blitting a 16MU source, this would allow the video to be visible, and avoid the performance penalties of option (1).  We would then call this from VideoOutput::paintEvent.

* On-target testing
1. Ensure that Phonon front- and back-end libraries are included in the SIS file.
2. Add musicplayer.exe and mediaplayer.exe to the FluidLauncher
3. Ensure that both apps can be launched, and that we can somehow get trace output from the MMF backend onto the PC for analysis.

* Trace for on-target testing
Do we need to connect up the TRACE_* macros to another logging output (e.g. file / Flogger / UTrace etc)?

* Implement audio effects

* Support for network streaming playback
The main question here is how best to implement the MIME type detection for streams.  The OpenUrlL functions only take a URL, whereas the corresponding OpenFileL functions have overloads for filenames and for open RFile handles.  This is because files support random access whereas streams do not.  A naieve approach to MIME type detection for streams is as follows; is there a more efficient approach?
	1. Open network connection
	2. Download header
	3. Detect MIME type and create AbstractMediaPlayer instance
	4. Close network connection
	5. Pass URL to MMF client utility, which will then re-open the stream
An alternative approach is to always create a VideoPlayer when passed an RTSP URL, and then modify VideoPlayer::hasVideo to check CVideoPlayerUtility::VideoMimeTypeL before returning.  This way, we would always use CVideoPlayerUtility for RTSP streaming, whether the source is audio or video.  Well-behaved client apps, however, should check MediaObject::hasVideo before creating the UI - and therefore the VideoWidget would only be connected if the source is actually a video stream.

* Performance analysis
Compare video frame rate obtained using default S60 media player and Qt demo apps

* Implement MMF::Backend::disconnectNodes
This should probably be left for now, particularly until audio effects have been implemented.  This is because the node connection mechanism may need to be refactored slightly once we start building up longer graphs (e.g. MediaObject -> Effect -> Effect -> AudioOutput).

* Before merging, ensure the UID3 is properly allocated, see the .pro file.

* Metadata is not implemented.

